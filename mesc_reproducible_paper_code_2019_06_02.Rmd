---
title: "Segregation Components Paper Code"
author: "Katherine Rose Wolf"
date: "June 12, 2019"
output: html_document
---

# CODE SETUP

```{r load packages}

library(rmarkdown)
library(knitr)
library(plyr)
library(data.table)
library(Hmisc)
library(extrafontdb)
library(extrafont)
library(NADA)
library(grid)
library(gridExtra)
library(lattice)
library(tmap)
library(sf)
library(tidycensus)
library(tigris)
library(rgeos)
library(sjPlot)
library(stargazer)
library(readxl)
library(tidyverse)

```


```{r rmarkdown options, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```


```{r census api key and options for tidycensus}

# install the census api key
census_api_key("eae31d12c8d9c2c9ee288e096e0c03830744aaef", 
               install = TRUE, 
               overwrite = TRUE)

readRenviron("~/.Renviron")

# have tidycensus store old shapefiles for future use
options(tigris_use_cache = TRUE)

```

```{r functions for later use}

# function to convert column names to snake case
column_name_fixer <-
  function(tibble) {
  new_names <-
    tibble %>%
    colnames() %>%  # gets the column names from the tibble
    tolower() %>%  # converts the column names to lowercase
    {gsub(" ", "_", .)}  # replaces spaces with "_"
  colnames(tibble) <-
    new_names  # rename the columns in the original tibble
  return(tibble)
  }

# create function that downloads files
file_downloader <-
  function(desired_filename_as_string, 
           web_address_as_string, 
           folder_as_string) {
    
    path <-  # specify the file path
      file.path(
        folder_as_string,
        desired_filename_as_string) 
    
    if(!file.exists(path))  # checks if file exists already
      download.file(url = web_address_as_string,  # if not, downloads/saves file
                    destfile = path, 
                    mode = "wb")
  }

```


# CREATE SUBDIRECTORIES

```{r create subdirectories}
if(!dir.exists("raw_data"))
  dir.create("raw_data")

if(!dir.exists("intermediate_data"))
  dir.create("intermediate_data")
```

# LOAD NECESSARY FILES

```{r census data, results = "hide"}

# last updated by census bureau 	19-Jul-2012 07:01	391M

if(
  !file.exists(
    file.path(
      "intermediate_data", 
      "census_data_shapefile.rdata"
      )
    )
) {
  # download zip file of census dp1 shapefiles
  file_downloader(
    desired_filename_as_string = "tract_2010_census_dp1.zip",
    web_address_as_string = 
      "http://www2.census.gov/geo/tiger/TIGER2010DP1/Tract_2010Census_DP1.zip", 
    folder_as_string = "raw_data"
    )

# unzip it to the intermediate file directory
  unzip(
    file.path(
      "raw_data", 
      "tract_2010_census_dp1.zip"), 
    exdir = "intermediate_data")

  # read the shapefile
  census_data_shapefile <- 
    read_sf(
      file.path(
        "intermediate_data", 
        "Tract_2010Census_DP1.shp"
        )
      )
  
  # fix column names
  census_data_shapefile <-
    column_name_fixer(
      census_data_shapefile
    )


  # save the shapefile
  save(
    census_data_shapefile,
    file = file.path(
      "intermediate_data", 
      "census_data_shapefile.rdata"
    )
  )

  # remove the shapefile from memory
  rm(census_data_shapefile)
  gc()
}

```


```{r ruca data}

if(
  !file.exists(
    file.path(
      "intermediate_data", 
      "ruca_2010.rdata"
      )
    )
  ) {
  file_downloader(
    desired_filename_as_string = "ruca_2010_raw.xlsx", 
    web_address_as_string = 
      "https://www.ers.usda.gov/webdocs/DataFiles/53241/ruca2010.xlsx?v=0", 
    folder_as_string = "raw_data"
    )

  ruca_2010_raw <- 
    read_xlsx(
      file.path(
        "raw_data", 
        "ruca_2010_raw.xlsx"
        )
      )
  
  # fix column names
  ruca_2010 <-
    column_name_fixer(
      ruca_2010_raw
    )

  # save the shapefile
  save(
    ruca_2010,
    file = file.path(
      "intermediate_data", 
      "ruca_2010.rdata"
    )
  )

  # remove the shapefile from memory
  rm(ruca_2010_raw, ruca_2010)
  gc()
}

```


```{r speciation parameter codes, results = "hide"}

if(
  !file.exists(
    file.path(
      "intermediate_data", 
      "speciation_parameter_codes.rdata"
      )
    )
  ) {
  
  # download the speciation paramter codes
  file_downloader(
    desired_filename_as_string = "speciation_parameter_codes.csv",
    web_address_as_string = "https://aqs.epa.gov/aqsweb/documents/codetables/methods_speciation.csv", 
    folder_as_string = "raw_data"
    )

  # read the parameter codes into memory
  speciation_parameter_codes <- 
    read_csv(
      file.path("raw_data", 
                "speciation_parameter_codes.csv"
                )
    )
  
  # fix column names
  speciation_parameter_codes <-
    column_name_fixer(
     speciation_parameter_codes
    )

  # save the rdata file
  save(
    speciation_parameter_codes,
    file = file.path(
      "intermediate_data", 
      "speciation_parameter_codes.rdata"
    )
  )

  # remove the rdata from memory
  rm(speciation_parameter_codes)
  gc()
}

```

## air pollution data files

```{r pm2.5 total frm}

if(
  !file.exists(
    file.path(
      "intermediate_data", 
      "big_pm_25_frm_tibble.rdata"
      )
    )
  ) {

  # make list of files to download
  pm_25_frm_files <- 
    c("https://aqs.epa.gov/aqsweb/airdata/daily_88101_2005.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2006.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2007.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2008.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2009.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2010.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2011.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2012.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2013.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2014.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2015.zip")
  
  
  # make a list of filenames for the downloaded data using the above filenames
  list_of_pm_25_frm_zip_filenames <-  # make list of what the filenames will be
    map_chr(pm_25_frm_files,  # witness the `map` function
            str_extract, 
            "daily_.+\\.zip")   # witness the regular expression!
  
  # download the files
  map2(list_of_pm_25_frm_zip_filenames, 
       pm_25_frm_files, 
       file_downloader, 
       folder_as_string = "raw_data")
  
  # unzip all the files and save them to disk
  map(
    file.path(
      "raw_data",
      list_of_pm_25_frm_zip_filenames
      ),
    unzip,
    exdir = "intermediate_data"
    )
  
  # replace ".zip" with ".csv" in list_of_pm_25_frm_zip_filenames
  list_of_pm_25_frm_csv_filenames <-
    map(list_of_pm_25_frm_zip_filenames,
        str_replace,
        "zip",
        "csv")
  
  # make list of tibble names by removing the ".zip" extension
  list_of_pm_25_frm_tibble_names <-
    map(list_of_pm_25_frm_zip_filenames,
        str_replace,
        ".zip",
        "")
  
  # read .csv files into tibbles!
  if(
    !file.exists(
      file.path(
        "intermediate_data",
        "list_of_pm_25_frm_tibbles.rdata"
        )
      )
    ) {  # checks if tibbles already exist
    list_of_pm_25_frm_tibbles <-  # if not reads .csv files into tibbles
      map(
        file.path(
          "intermediate_data",
          list_of_pm_25_frm_csv_filenames),
        read_csv
        )
    names(list_of_pm_25_frm_tibbles) <-  # names the tibbles
      list_of_pm_25_frm_tibble_names
    save(
      list_of_pm_25_frm_tibbles,  # saves the tibbles to disk to avoid doing this again
      file = file.path(
        "intermediate_data",
        "list_of_pm_25_frm_tibbles.rdata"
        )
      )
    
  } else {
      load(
        file = file.path(
        "intermediate_data",
        "list_of_pm_25_frm_tibbles.rdata"
        )
        )  # loads the tibbles if they don't already exist
  }
  
  # fix column names
  list_of_pm_25_frm_tibbles <-
    map(list_of_pm_25_frm_tibbles,
        column_name_fixer)
  
  # combine air data tibbles into one big tibble
  big_pm_25_frm_tibble <-
    bind_rows(list_of_pm_25_frm_tibbles)
  
  # remove non-needed columns
  big_pm_25_frm_tibble <- 
    big_pm_25_frm_tibble %>%
    select(-c(
      pollutant_standard, 
      units_of_measure, 
      aqi, 
      method_name, 
      local_site_name, 
      address, 
      county_name)
      )
  
  # save all air data to disk
  save(
      big_pm_25_frm_tibble,  # saves the tibbles to disk to avoid doing this again
      file = file.path(
        "intermediate_data",
        "big_pm_25_frm_tibble.rdata"
        )
      )
  
  # memory and disk clearance --------------------------------------------------
  
  # delete individual .csv files from disk
  map(
    file.path(
      "intermediate_data",
      list_of_pm_25_frm_csv_filenames
      ),
    file.remove
    )
  
  # remove list of tibbles from memory
  rm(list_of_pm_25_frm_tibbles)
  
  # remove big tibble from memory
  rm(big_pm_25_frm_tibble)
  
  # clear memory
  gc()

}

```


```{r functionalize the speciation}

speciator <- 
  function(speciation_file_link) {
    
    # extract the file name from the link
    speciation_zip_file_name <-
      str_extract(
        speciation_file_link,
        "daily_.+\\.zip"
        )
    
    # create rdata file name
    speciation_rdata_file_name <- 
      str_replace(
        speciation_zip_file_name,
        "zip",
        "rdata"
        )
    
     if(
      !file.exists(  # checks if tibble already exists
        file.path(
          "intermediate_data",
          speciation_rdata_file_name
          )
        )
      ) {
       
       # download the file
       file_downloader(
         desired_filename_as_string = speciation_zip_file_name,
         web_address_as_string = speciation_file_link,
         folder_as_string = "raw_data"
       )
    
       # unzip the file
       unzip(
         file.path(
           "raw_data",
           speciation_zip_file_name
           ), 
         exdir = "intermediate_data"
         )
      
       # replace ".zip" with ".csv" in list_of_speciation_zip_filenames
       speciation_csv_file_name <- 
         str_replace(
           speciation_zip_file_name, 
           "zip", 
           "csv")
      
       speciation_tibble_name <- 
         str_replace(
           speciation_zip_file_name, 
           ".zip",
           ""
         )
      
       # read .csv file into a tibble
         speciation_tibble <- 
           read_csv(
             file.path(
               "intermediate_data",
               speciation_csv_file_name
               )
             )
         
       # fix column names
       speciation_tibble <-
         column_name_fixer(
           speciation_tibble
         )
        
       # keep only actual component measurements and necessary columns
       speciation_tibble_shrunk <- 
         speciation_tibble %>% 
         filter(parameter_code > 88100) %>% 
         select(
           -c(
             pollutant_standard, 
             units_of_measure, 
             aqi, 
             method_name, 
             local_site_name, 
             address, 
             county_name)
         )
       
       # rename it to its filename
       assign(
         speciation_tibble_name, 
         speciation_tibble_shrunk
       )
        
       # save the result to disk
       save(
         list = speciation_tibble_name,
         file = 
           file.path(
             "intermediate_data",
             speciation_rdata_file_name
             )
       )
       
       # delete .csv file from disk
       map(
         file.path(
           "intermediate_data",
           speciation_csv_file_name
           ),
         file.remove
         )
      
       # remove files
       rm(
         speciation_tibble, 
         speciation_tibble_shrunk)
       gc()
     }
    
    # remove files
    rm(
      speciation_zip_file_name, 
      speciation_rdata_file_name
    )
    gc()
  }

```


```{r implement speciator en masse}

# make list of speciation web addresses
speciation_files <-
  c("https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2005.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2006.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2007.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2008.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2009.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2010.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2011.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2012.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2013.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2014.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2015.zip")

map(
  .x = speciation_files, 
  .f = speciator
)

```


```{r combine the air pollution data files}

if(
  !file.exists(  # checks if tibble already exists
    file.path(
      "intermediate_data",
      "big_speciation_tibble.rdata"
      )
    )
  ) {
  # make list of speciation file names except the file names of the first two
  speciation_file_names_except_2005_2006 <- 
    sprintf("daily_SPEC_%d.rdata", 
            seq(2007, 2015, 1))

  # load 2005 speciation file
  load(
    file.path(
      "intermediate_data", 
      "daily_SPEC_2005.rdata"
      )
    )
  
  daily_SPEC_2005
  
  # load 2006 speciation file
  load(
    file.path(
      "intermediate_data", 
      "daily_SPEC_2006.rdata"
      )
    )
  
  # create the first edition of the big speciation tibble by a row bind
  big_speciation_tibble <- 
    bind_rows(
      daily_SPEC_2005, 
      daily_SPEC_2006
    )
  
  # remove the 2005 and 2006 tibbles from memory
  rm(
    daily_SPEC_2005, 
    daily_SPEC_2006)
  gc()
  
  # make a function to bind the rest of the speciation tibbles
  speciebinder <- 
    function(speciation_file_name) {
      
      # make variable of tibble name
      speciation_tibble_name <- 
        str_replace(
          speciation_file_name, 
          ".rdata",
          ""
          )
      
      # load next speciation file
      load(
        file.path(
          "intermediate_data", 
          speciation_file_name
        )
      )
      
      # bind the speciation file to the big tibble
      big_speciation_tibble <<- 
        bind_rows(  
          big_speciation_tibble, 
          eval(as.symbol(speciation_tibble_name)))
      
      # remove the speciation file and clear the memory
      rm(speciation_file_name, 
         list = speciation_tibble_name)
      gc()
      
    }
  
  # make the big speciation dataset
  speciebinder("daily_SPEC_2007.rdata")
  gc()
  speciebinder("daily_SPEC_2008.rdata")
  gc()
  speciebinder("daily_SPEC_2009.rdata")
  gc()
  speciebinder("daily_SPEC_2010.rdata")
  gc()
  speciebinder("daily_SPEC_2011.rdata")
  gc()
  speciebinder("daily_SPEC_2012.rdata")
  gc()
  speciebinder("daily_SPEC_2013.rdata")
  gc()
  speciebinder("daily_SPEC_2014.rdata")
  gc()
  speciebinder("daily_SPEC_2015.rdata")
  gc()
  
  # save the big speciation dataset
  save(
    big_speciation_tibble, 
    file = 
      file.path(
        "intermediate_data", 
        "big_speciation_tibble.rdata"
        )
  )
  
  # remove non-needed files from memory
  rm(speciation_files, 
     speciation_file_names_except_2005_2006,
     big_speciation_tibble)
  gc()
  }

```


```{r join pm25 total and speciation data}
# 
# load(
#   file.path(
#     "intermediate_data", 
#     "big_pm_25_frm_tibble.rdata"
#   )
# )
# 
# load(
#   file.path(
#     "intermediate_data", 
#     "big_speciation_tibble.rdata"
#   )
# )
#   

```

## clean air pollution data

## american community survey data
