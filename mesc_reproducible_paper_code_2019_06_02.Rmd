---
title: "Segregation Components Paper Code"
author: "Katherine Rose Wolf"
date: "June 12, 2019"
output: html_document
---

# CODE SETUP

```{r load packages}

library(rmarkdown)
library(knitr)
library(plyr)
library(data.table)
library(Hmisc)
library(extrafontdb)
library(extrafont)
library(NADA)
library(grid)
library(gridExtra)
library(lattice)
library(tmap)
library(sf)
library(tidycensus)
library(tigris)
library(rgeos)
library(sjPlot)
library(stargazer)
library(readxl)
library(tidyverse)
library(totalcensus)

```


```{r rmarkdown options, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```


```{r census api key and options for tidycensus}

# install the census api key
census_api_key("eae31d12c8d9c2c9ee288e096e0c03830744aaef", 
               install = TRUE, 
               overwrite = TRUE)

readRenviron("~/.Renviron")

# have tidycensus store old shapefiles for future use
options(tigris_use_cache = TRUE)

```


```{r functions for later use}

# function to convert column names to snake case
column_name_fixer <-
  function(tibble) {
  new_names <-
    tibble %>%
    colnames() %>%  # gets the column names from the tibble
    tolower() %>%  # converts the column names to lowercase
    {gsub(" ", "_", .)}  # replaces spaces with "_"
  colnames(tibble) <-
    new_names  # rename the columns in the original tibble
  return(tibble)
  }

# create function that downloads files
file_downloader <-
  function(desired_filename_as_string, 
           web_address_as_string, 
           folder_as_string) {
    
    path <-  # specify the file path
      file.path(
        folder_as_string,
        desired_filename_as_string) 
    
    if(!file.exists(path))  # checks if file exists already
      download.file(url = web_address_as_string,  # if not, downloads/saves file
                    destfile = path, 
                    mode = "wb")
  }

```

# CREATE SUBDIRECTORIES

```{r create subdirectories}
if(!dir.exists("raw_data"))
  dir.create("raw_data")

if(!dir.exists("intermediate_data"))
  dir.create("intermediate_data")
```

# LOAD NECESSARY FILES

```{r census data, results = "hide"}

# last updated by census bureau 	19-Jul-2012 07:01	391M

if(
  !file.exists(
    file.path(
      "intermediate_data", 
      "census_data_shapefile.rdata"
      )
    )
) {
  # download zip file of census dp1 shapefiles
  file_downloader(
    desired_filename_as_string = "tract_2010_census_dp1.zip",
    web_address_as_string = 
      "http://www2.census.gov/geo/tiger/TIGER2010DP1/Tract_2010Census_DP1.zip", 
    folder_as_string = "raw_data"
    )

# unzip it to the intermediate file directory
  unzip(
    file.path(
      "raw_data", 
      "tract_2010_census_dp1.zip"), 
    exdir = "intermediate_data")

  # read the shapefile
  census_data_shapefile <- 
    read_sf(
      file.path(
        "intermediate_data", 
        "Tract_2010Census_DP1.shp"
        )
      )
  
  # fix column names
  census_data_shapefile <-
    column_name_fixer(
      census_data_shapefile
    )


  # save the shapefile
  save(
    census_data_shapefile,
    file = file.path(
      "intermediate_data", 
      "census_data_shapefile.rdata"
    )
  )

  # remove the shapefile from memory
  rm(census_data_shapefile)
  gc()
}

```


```{r ruca data}

if(
  !file.exists(
    file.path(
      "intermediate_data", 
      "ruca_2010.rdata"
      )
    )
  ) {
  file_downloader(
    desired_filename_as_string = "ruca_2010_raw.xlsx", 
    web_address_as_string = 
      "https://www.ers.usda.gov/webdocs/DataFiles/53241/ruca2010.xlsx?v=0", 
    folder_as_string = "raw_data"
    )

  ruca_2010_raw <- 
    read_xlsx(
      file.path(
        "raw_data", 
        "ruca_2010_raw.xlsx"
        )
      )
  
  # fix column names
  ruca_2010 <-
    column_name_fixer(
      ruca_2010_raw
    )

  # save the shapefile
  save(
    ruca_2010,
    file = file.path(
      "intermediate_data", 
      "ruca_2010.rdata"
    )
  )

  # remove the shapefile from memory
  rm(ruca_2010_raw, ruca_2010)
  gc()
}

```


```{r speciation parameter codes, results = "hide"}

if(
  !file.exists(
    file.path(
      "intermediate_data", 
      "speciation_parameter_codes.rdata"
      )
    )
  ) {
  
  # download the speciation paramter codes
  file_downloader(
    desired_filename_as_string = "speciation_parameter_codes.csv",
    web_address_as_string = "https://aqs.epa.gov/aqsweb/documents/codetables/methods_speciation.csv", 
    folder_as_string = "raw_data"
    )

  # read the parameter codes into memory
  speciation_parameter_codes <- 
    read_csv(
      file.path("raw_data", 
                "speciation_parameter_codes.csv"
                )
    )
  
  # fix column names
  speciation_parameter_codes <-
    column_name_fixer(
     speciation_parameter_codes
    )

  # save the rdata file
  save(
    speciation_parameter_codes,
    file = file.path(
      "intermediate_data", 
      "speciation_parameter_codes.rdata"
    )
  )

  # remove the rdata from memory
  rm(speciation_parameter_codes)
  gc()
}

```


```{r make parameter and species lists}

load(
  file = 
    file.path(
      "intermediate_data", 
      "speciation_parameter_codes.rdata"
      )
)

# make a list of all the species and their codes
species_and_codes <- 
  speciation_parameter_codes %>% 
  select(parameter, parameter_code) %>% 
  distinct

# make a list of the organic carbon species and codes
organic_carbon_rows <- 
  species_and_codes %>% 
  filter(str_detect(parameter, "OC"))

# make a numeric vector of the organic carbon species and codes
organic_carbon_codes <-
  organic_carbon_rows %>% 
  select(parameter_code) %>% 
  pull()

save(
  species_and_codes, 
  file = 
    file.path(
      "intermediate_data", 
      "species_and_codes.rdata"
    )
  )

save(
  organic_carbon_codes, 
  file = 
    file.path(
      "intermediate_data", 
      "organic_carbon_codes.rdata"
    )
  )

# remove created data from memory
rm(
  organic_carbon_codes, 
  speciation_parameter_codes,
  species_and_codes)
gc()

```


## air pollution data files

```{r pm2.5 total frm}

if(
  !file.exists(
    file.path(
      "intermediate_data", 
      "big_pm_25_frm_tibble.rdata"
      )
    )
  ) {

  # make list of files to download
  pm_25_frm_files <- 
    c("https://aqs.epa.gov/aqsweb/airdata/daily_88101_2005.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2006.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2007.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2008.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2009.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2010.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2011.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2012.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2013.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2014.zip",
      "https://aqs.epa.gov/aqsweb/airdata/daily_88101_2015.zip")
  
  
  # make a list of filenames for the downloaded data using the above filenames
  list_of_pm_25_frm_zip_filenames <-  # make list of what the filenames will be
    map_chr(pm_25_frm_files,  # witness the `map` function
            str_extract, 
            "daily_.+\\.zip")   # witness the regular expression!
  
  # download the files
  map2(list_of_pm_25_frm_zip_filenames, 
       pm_25_frm_files, 
       file_downloader, 
       folder_as_string = "raw_data")
  
  # unzip all the files and save them to disk
  map(
    file.path(
      "raw_data",
      list_of_pm_25_frm_zip_filenames
      ),
    unzip,
    exdir = "intermediate_data"
    )
  
  # replace ".zip" with ".csv" in list_of_pm_25_frm_zip_filenames
  list_of_pm_25_frm_csv_filenames <-
    map(list_of_pm_25_frm_zip_filenames,
        str_replace,
        "zip",
        "csv")
  
  # make list of tibble names by removing the ".zip" extension
  list_of_pm_25_frm_tibble_names <-
    map(list_of_pm_25_frm_zip_filenames,
        str_replace,
        ".zip",
        "")
  
  # read .csv files into tibbles!
  if(
    !file.exists(
      file.path(
        "intermediate_data",
        "list_of_pm_25_frm_tibbles.rdata"
        )
      )
    ) {  # checks if tibbles already exist
    list_of_pm_25_frm_tibbles <-  # if not reads .csv files into tibbles
      map(
        file.path(
          "intermediate_data",
          list_of_pm_25_frm_csv_filenames),
        read_csv
        )
    names(list_of_pm_25_frm_tibbles) <-  # names the tibbles
      list_of_pm_25_frm_tibble_names
    save(
      list_of_pm_25_frm_tibbles,  # saves the tibbles to disk to avoid doing this again
      file = file.path(
        "intermediate_data",
        "list_of_pm_25_frm_tibbles.rdata"
        )
      )
    
  } else {
      load(
        file = file.path(
        "intermediate_data",
        "list_of_pm_25_frm_tibbles.rdata"
        )
        )  # loads the tibbles if they don't already exist
  }
  
  # fix column names
  list_of_pm_25_frm_tibbles <-
    map(list_of_pm_25_frm_tibbles,
        column_name_fixer)
  
  # combine air data tibbles into one big tibble
  big_pm_25_frm_tibble <-
    bind_rows(list_of_pm_25_frm_tibbles)
  
  # remove non-needed columns
  big_pm_25_frm_tibble <- 
    big_pm_25_frm_tibble %>%
    select(-c(
      pollutant_standard, 
      units_of_measure, 
      aqi, 
      method_name, 
      local_site_name, 
      address, 
      county_name)
      )
  
  # save all air data to disk
  save(
      big_pm_25_frm_tibble,  # saves the tibbles to disk to avoid doing this again
      file = file.path(
        "intermediate_data",
        "big_pm_25_frm_tibble.rdata"
        )
      )
  
  # memory and disk clearance --------------------------------------------------
  
  # delete individual .csv files from disk
  map(
    file.path(
      "intermediate_data",
      list_of_pm_25_frm_csv_filenames
      ),
    file.remove
    )
  
  # remove list of tibbles from memory
  rm(list_of_pm_25_frm_tibbles)
  
  # remove big tibble from memory
  rm(big_pm_25_frm_tibble)
  
  # clear memory
  gc()

}

```


```{r functionalize the speciation}

speciator <- 
  function(speciation_file_link) {
    
    # extract the file name from the link
    speciation_zip_file_name <-
      str_extract(
        speciation_file_link,
        "daily_.+\\.zip"
        )
    
    # create rdata file name
    speciation_rdata_file_name <- 
      str_replace(
        speciation_zip_file_name,
        "zip",
        "rdata"
        )
    
     if(
      !file.exists(  # checks if tibble already exists
        file.path(
          "intermediate_data",
          speciation_rdata_file_name
          )
        )
      ) {
       
       # download the file
       file_downloader(
         desired_filename_as_string = speciation_zip_file_name,
         web_address_as_string = speciation_file_link,
         folder_as_string = "raw_data"
       )
    
       # unzip the file
       unzip(
         file.path(
           "raw_data",
           speciation_zip_file_name
           ), 
         exdir = "intermediate_data"
         )
      
       # replace ".zip" with ".csv" in list_of_speciation_zip_filenames
       speciation_csv_file_name <- 
         str_replace(
           speciation_zip_file_name, 
           "zip", 
           "csv")
      
       speciation_tibble_name <- 
         str_replace(
           speciation_zip_file_name, 
           ".zip",
           ""
         )
      
       # read .csv file into a tibble
         speciation_tibble <- 
           read_csv(
             file.path(
               "intermediate_data",
               speciation_csv_file_name
               )
             )
         
       # fix column names
       speciation_tibble <-
         column_name_fixer(
           speciation_tibble
         )
       
       # load organic carbon codes
       if (!exists("organic_carbon_codes")) {
       load(
         file = 
           file.path(
             "intermediate_data", 
             "organic_carbon_codes.rdata"
             )
         )
       }
        
       # keep only actual component measurements and necessary columns
       speciation_tibble_shrunk <- 
         speciation_tibble %>% 
         filter(parameter_code > 88100) %>% 
         filter(!(parameter_code %in% organic_carbon_codes)) %>% 
         select(
           -c(
             pollutant_standard, 
             units_of_measure, 
             aqi, 
             method_name, 
             local_site_name, 
             address, 
             county_name)
         )
       
       # rename it to its filename
       assign(
         speciation_tibble_name, 
         speciation_tibble_shrunk
       )
        
       # save the result to disk
       save(
         list = speciation_tibble_name,
         file = 
           file.path(
             "intermediate_data",
             speciation_rdata_file_name
             )
       )
       
       # delete .csv file from disk
       map(
         file.path(
           "intermediate_data",
           speciation_csv_file_name
           ),
         file.remove
         )
      
       # remove files
       rm(
         speciation_tibble, 
         speciation_tibble_shrunk)
       gc()
     }
    
    # remove files
    rm(
      speciation_zip_file_name, 
      speciation_rdata_file_name
    )
    gc()
  }

```


```{r implement speciator en masse}

# make list of speciation web addresses
speciation_files <-
  c("https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2005.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2006.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2007.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2008.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2009.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2010.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2011.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2012.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2013.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2014.zip",
    "https://aqs.epa.gov/aqsweb/airdata/daily_SPEC_2015.zip")

map(
  .x = speciation_files, 
  .f = speciator
)

```


```{r combine the air pollution data files}

if(
  !file.exists(  # checks if tibble already exists
    file.path(
      "intermediate_data",
      "big_speciation_tibble.rdata"
      )
    )
  ) {
  # make list of speciation file names except the file names of the first two
  speciation_file_names_except_2005_2006 <- 
    sprintf("daily_SPEC_%d.rdata", 
            seq(2007, 2015, 1))

  # load 2005 speciation file
  load(
    file.path(
      "intermediate_data", 
      "daily_SPEC_2005.rdata"
      )
    )
  
  # load 2006 speciation file
  load(
    file.path(
      "intermediate_data", 
      "daily_SPEC_2006.rdata"
      )
    )
  
  # create the first edition of the big speciation tibble by a row bind
  big_speciation_tibble <- 
    bind_rows(
      daily_SPEC_2005, 
      daily_SPEC_2006
    )
  
  # remove the 2005 and 2006 tibbles from memory
  rm(
    daily_SPEC_2005, 
    daily_SPEC_2006)
  gc()
  
  # make a function to bind the rest of the speciation tibbles
  speciebinder <- 
    function(speciation_file_name) {
      
      # make variable of tibble name
      speciation_tibble_name <- 
        str_replace(
          speciation_file_name, 
          ".rdata",
          ""
          )
      
      # load next speciation file
      load(
        file.path(
          "intermediate_data", 
          speciation_file_name
        )
      )
      
      # bind the speciation file to the big tibble
      big_speciation_tibble <<- 
        bind_rows(  
          big_speciation_tibble, 
          eval(as.symbol(speciation_tibble_name)))
      
      # remove the speciation file and clear the memory
      rm(speciation_file_name, 
         list = speciation_tibble_name)
      gc()
      
    }
  
  # make the big speciation dataset
  speciebinder("daily_SPEC_2007.rdata")
  gc()
  speciebinder("daily_SPEC_2008.rdata")
  gc()
  speciebinder("daily_SPEC_2009.rdata")
  gc()
  speciebinder("daily_SPEC_2010.rdata")
  gc()
  speciebinder("daily_SPEC_2011.rdata")
  gc()
  speciebinder("daily_SPEC_2012.rdata")
  gc()
  speciebinder("daily_SPEC_2013.rdata")
  gc()
  speciebinder("daily_SPEC_2014.rdata")
  gc()
  speciebinder("daily_SPEC_2015.rdata")
  gc()
  
  # save the big speciation dataset
  save(
    big_speciation_tibble, 
    file = 
      file.path(
        "intermediate_data", 
        "big_speciation_tibble.rdata"
        )
  )
  
  # remove non-needed files from memory
  rm(speciation_files, 
     speciation_file_names_except_2005_2006,
     big_speciation_tibble)
  gc()
  }

```


```{r join pm25 total and speciation data}

# if(
#   !file.exists(  # checks if tibble already exists
#     file.path(
#       "intermediate_data",
#       "big_air_tibble.rdata"
#       )
#     )
#   ) {
#   
#   # load the total pm2.5 tibble
#   load(
#     file.path(
#       "intermediate_data",
#       "big_pm_25_frm_tibble.rdata"
#     )
#   )
# 
#   # load the pm2.5 speciation tibble
#   load(
#     file.path(
#       "intermediate_data",
#       "big_speciation_tibble.rdata"
#     )
#   )
# 
#   # and in the darkness bind them
#   big_air_tibble <- 
#     bind_rows(  
#       big_pm_25_frm_tibble,
#       big_speciation_tibble)
#   
#   # remove extraneous files
#   rm(big_pm_25_frm_tibble, 
#      big_speciation_tibble)
#   gc()
#   
#   # save the big tibble
#   save(
#     big_air_tibble, 
#     file = 
#       file.path(
#         "intermediate_data", 
#         "big_air_tibble.rdata"
#       ))
#   
# }

```

## american community survey data

```{r american community survey data}

# set path to census data
Sys.setenv(PATH_TO_CENSUS = tempdir())
# 
# acs_data_2008_2012_via_totalcensus <-
#   read_acs5year(
#     year = 2012,
#     states = "AL",
#     table_contents =
#       "B01003",
#     summary_level = "tract",
#     with_margin = TRUE
# )



# #### raw acs data import ####
#
# variable_names <-
#   readLines(
#     "acs_2013_2017_data_supplements/comma_separated_variables.csv")
# variable_names
#
# variable_names_to_include <-
#   readLines(
#     "acs_2013_2017_data_supplements/variable_names_to_include.csv")
# variable_names_to_include
#
# variable_names_to_exclude <-
#   readLines("acs_2013_2017_data_supplements/variable_names_to_exclude.csv"
#             )
# variable_names_to_exclude
#
# true_variable_candidates <-
#   variable_names[
#     grepl(
#       paste(
#         variable_names_to_include,
#         collapse="|"),
#       variable_names)]
#
# true_variable_candidates
#
# variable_names_for_totalcensus <-
#   true_variable_candidates[
#     !grepl(
#       paste(
#         variable_names_to_exclude,
#         collapse="|"),
#       true_variable_candidates)]
#
# additional_exclusions <-
#   c("\\.",
#     "B15002A",
#     "B15002B",
#     "B15002C",
#     "B15002D",
#     "B15002E",
#     "B15002F",
#     "B15002G",
#     "B15002H",
#     "B15002I",
#     "B21001A",
#     "B21001B",
#     "B21001C",
#     "B21001D",
#     "B21001E",
#     "B21001F",
#     "B21001G",
#     "B21001H",
#     "B21001I")
#
# final_variable_names_for_totalcensus <-
#   variable_names_for_totalcensus[
#     !grepl(
#       paste(
#         additional_exclusions,
#         collapse="|"),
#       variable_names_for_totalcensus
#       )
#     ]
#
# final_variable_names_for_totalcensus
#
# # set_path_to_census("acs_2013_2017_data")
#
# acs_data_2013_2017_via_totalcensus <-
#   read_acs5year(
#     year = 2017,
#     states = "KS",
#     table_contents =
#       final_variable_names_for_totalcensus,
#     summary_level = "block group",
#     with_margin = TRUE
# )
#
#
# save(
#   acs_data_2013_2017_via_totalcensus,
#   file = "acs_data_2013_2017_via_totalcensus.rdata"
#   )
#
# write.csv(
#   acs_data_2013_2017_via_totalcensus,
#   file = "acs_data_2013_2017_via_totalcensus.csv"
#   )


# acs_pop_no_marg <- 
#   ACS_simplified_raw_data[c <- c("GEOID","B00001e1")]
# 
# acs_earnings_no_marg <- ACS_raw_data[c("GEOID","B20001e1","B20001e2","B20001e3","B20001e4","B20001e5","B20001e6","B20001e7","B20001e8","B20001e9","B20001e10","B20001e11","B20001e12","B20001e13","B20001e14","B20001e15","B20001e16","B20001e17","B20001e18","B20001e19","B20001e20","B20001e21","B20001e22","B20001e23","B20001e24","B20001e25","B20001e26","B20001e27","B20001e28","B20001e29","B20001e30","B20001e31","B20001e32","B20001e33","B20001e34","B20001e35","B20001e36","B20001e37","B20001e38","B20001e39","B20001e40","B20001e41","B20001e42","B20001e43")]
# 
# acs_median_earnings_no_marg <- ACS_raw_data[c("GEOID","B20002e1")]
# 
# # education variables
# acs_education_variables <- ACS_simplified_raw_data[c("GEOID","B15003e1","B15003m1","B15003e2","B15003m2","B15003e3","B15003m3","B15003e4","B15003m4","B15003e5","B15003m5","B15003e6","B15003m6","B15003e7","B15003m7","B15003e8","B15003m8","B15003e9","B15003m9","B15003e10","B15003m10","B15003e11","B15003m11","B15003e12","B15003m12","B15003e13","B15003m13","B15003e14","B15003m14","B15003e15","B15003m15","B15003e16","B15003m16","B15003e17","B15003m17","B15003e18","B15003m18","B15003e19","B15003m19","B15003e20","B15003m20","B15003e21","B15003m21","B15003e22","B15003m22","B15003e23","B15003m23","B15003e24","B15003m24","B15003e25","B15003m25")]
# 
# education_labels <- c("tract_ID","ed_pop","ed_pop_margin","ed_no_school","ed_no_school_margin","ed_nurse","ed_nurse_margin","ed_kinder","ed_kinder_margin","ed_1","ed_1_margin","ed_2","ed_2_margin","ed_3","ed_3_margin","ed_4","ed_4_margin","ed_5","ed_5_margin","ed_6","ed_6_margin","ed_7","ed_7_margin","ed_8","ed_8_margin","ed_9","ed_9_margin","ed_10","ed_10_margin","ed_11","ed_11_margin","ed_12","ed_12_margin","ed_hsdip","ed_hsdip_margin","ed_GED","ed_GED_margin","ed_<1_college","ed_<1_college_margin","ed_1+_college","ed_1+_college_margin","ed_associate","ed_associate_margin","ed_bachelor","ed_bachelor_margin","ed_master","ed_master_margin","ed_prof","ed_prof_marg","ed_doctor","ed_doctor_marg")
# 
# acs_education_variables_no_margins <- ACS_simplified_raw_data[c("GEOID","B15003e1","B15003e2","B15003e3","B15003e4","B15003e5","B15003e6","B15003e7","B15003e8","B15003e9","B15003e10","B15003e11","B15003e12","B15003e13","B15003e14","B15003e15","B15003e16","B15003e17","B15003e18","B15003e19","B15003e20","B15003e21","B15003e22","B15003e23","B15003e24","B15003e25")]
# # View(acs_education_variables_no_margins)
# 
# education_labels_no_margins <- c("GEOID","ed_pop","ed_no_school","ed_nurse","ed_kinder","ed_1","ed_2","ed_3","ed_4","ed_5","ed_6","ed_7","ed_8","ed_9","ed_10","ed_11","ed_12","ed_hsdip","ed_GED","ed_<1_college","ed_1+_college","ed_associate","ed_bachelor","ed_master","ed_prof","ed_doctor")
# 
# colnames(acs_education_variables_no_margins) <- education_labels_no_margins
# 
# # household value
# acs_median_househ_value_no_marg <- ACS_raw_data[c("GEOID","B25077e1")]
# 
# # household income
# acs_median_household_income_no_marg <- ACS_raw_data[c("GEOID","B19013e1")]
# 
# # poverty
# acs_poverty <- ACS_raw_data[c("GEOID","B17001e1","B17001e2")]
# 
# # unemployment
# acs_unemp_no_marg <- ACS_simplified_raw_data[c("GEOID","B23025e1","B23025e2","B23025e3","B23025e4","B23025e5","B23025e6","B23025e7")]




```


## clean air pollution data


